파일들을 먼저 확인해보겠습니다.좋습니다. 9강 노트북 내용을 확인했으니, 이제 지침에 맞춰 강의 원고를 작성해드리겠습니다.

---

# 9강: ETF 로우 데이터 수집 및 저장

안녕하세요, 여러분. 지난 강의까지는 국내 주식 데이터를 중심으로 한국투자증권 API 활용법과 데이터 수집·분석 기법을 다뤄왔습니다. 그 흐름을 이어서, 이번 시간부터는 조금 다른 방향으로 나아가보겠습니다. 바로 **ETF 분석**입니다.

ETF는 개별 종목과 달리 포트폴리오 자체를 상품화한 것이기 때문에, 분석 방식도 조금 다릅니다. 단순히 가격 차트만 보는 것이 아니라, 어떤 자산으로 구성되어 있는지, 괴리율은 어떤지, 운용 규모는 얼마나 되는지 등 여러 측면을 함께 봐야 합니다.

오늘 강의에서는 본격적인 분석에 앞서, **분석에 필요한 원재료(로우 데이터)**를 정의하고 수집해보겠습니다. 최소한의 스키마를 가진 CSV 파일로 저장해두면, 다음 강의에서 이 데이터를 읽어 들여 분석 지표를 계산할 수 있습니다.

---

## 이 강의의 목표

오늘 우리가 함께 해볼 작업은 크게 세 가지입니다.

**먼저**, ETF 분석에 필요한 핵심 데이터셋이 무엇인지 정의하겠습니다. ETF 기본 정보, 구성 종목, 가격 시계열 이렇게 세 가지가 핵심입니다.

**그다음**, 한국투자증권 API를 통해 실제로 데이터를 수집하는 방법을 살펴보겠습니다. 각 데이터셋마다 어떤 API를 호출해야 하는지, 어떤 파라미터를 넘겨야 하는지 차근차근 정리해보겠습니다.

**마지막으로**, 수집한 데이터를 최소한의 검증만 거친 뒤 CSV 파일로 저장하는 과정까지 완성하겠습니다. 이 파일들은 10강, 11강에서 분석 재료로 사용됩니다.

### 수집할 데이터

오늘 수집할 데이터는 다음과 같습니다.

| 데이터          | 파일명                           | 용도                   |
| --------------- | -------------------------------- | ---------------------- |
| ETF 기본 정보   | `data/raw/etf_info.csv`          | 상품 메타, AUM, NAV 등 |
| ETF 구성 종목   | `data/raw/holdings_{ticker}.csv` | 포트폴리오 구성 분석   |
| ETF 가격 시계열 | `data/raw/price_{ticker}.csv`    | 수익률/리스크 계산     |

### 이 강의에서 하지 않는 것

여기서 중요한 점은, 오늘은 **데이터 수집에만 집중**한다는 점입니다.

괴리율이 무엇인지, 추적오차가 의미하는 바가 무엇인지, 섹터별 분포가 어떻게 되는지, MDD나 Sharpe Ratio 같은 리스크 지표를 어떻게 계산하는지 등은 오늘 다루지 않습니다.

이런 금융 지표 계산과 해석은 모두 **10강과 11강**에서 다룰 예정입니다. 오늘은 그저 "분석에 필요한 재료를 깔끔하게 준비해두는 것"만으로도 충분합니다. 걱정하지 마세요. 구조만 한 번 제대로 잡아두면, 세부 해석은 천천히 채워 넣어도 됩니다.

---

## Step 0. KIS 공통 유틸 모듈 소개

본격적으로 데이터를 수집하기 전에, 먼저 전제 조건을 하나 짚고 가겠습니다.

이번 ETF 강의 시리즈에서는 한국투자증권 API 인증이나 토큰 발급, HTTP 요청 처리 같은 기초 구현 자체를 반복해서 설명하지 않습니다. 이런 부분은 이미 여러분이 이전 강의에서 충분히 다뤄왔다고 가정하고 시작하겠습니다.

대신, 공통으로 사용할 유틸리티 함수들을 `kis_utils.py`라는 모듈에 미리 준비해두었습니다. 이 모듈이 하는 일은 다음과 같습니다.

**먼저**, `.env` 파일에서 KIS API 키, 시크릿, 액세스 토큰을 읽어옵니다.

**그다음**, 토큰이 만료되었을 때 자동으로 재발급을 처리합니다.

**이어서**, `call_kis_get()`이라는 공통 헬퍼 함수로 KIS API 호출을 단순화했습니다. 토큰 만료 시 재시도 로직도 포함되어 있습니다.

**마지막으로**, ETF 코드를 넘기면 ETF 이름을 조회해주는 `get_etf_name_from_kis()` 같은 유틸리티도 포함되어 있습니다.

이렇게 공통 로직을 분리해두면, 오늘 강의에서는 **ETF 데이터 수집과 분석 로직에만 집중**할 수 있습니다. 세세한 API 통신 처리에 시간을 쏟지 않아도 되는 거죠.

### 모듈 임포트

자, 그럼 이제 필요한 모듈을 불러와보겠습니다.

```python
import pandas as pd
from datetime import date, datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

from kis_utils import (
    DATA_DIR,
    to_float,
    ensure_kis_token,
    call_kis_get,
    get_etf_name_from_kis,
)
```

여기서 `kis_utils`에서 가져온 함수들이 바로 아까 말씀드린 공통 유틸리티입니다. `DATA_DIR`은 데이터 저장 경로, `to_float`는 쉼표가 섞인 문자열을 float로 변환하는 헬퍼, `ensure_kis_token`은 토큰 존재를 보장하는 함수, `call_kis_get`은 KIS API 공통 호출 함수, `get_etf_name_from_kis`는 ETF 이름 조회 함수입니다.

### Step 0-1. 저장 디렉터리 설정

수집한 로우 데이터는 `data/raw/` 디렉터리에 저장하겠습니다. 이 디렉터리가 없으면 자동으로 만들어지도록 설정해두겠습니다.

```python
# 로우 데이터 저장 디렉터리
RAW_DATA_DIR = DATA_DIR / "raw"
RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)

print(f"RAW_DATA_DIR: {RAW_DATA_DIR}")
```

실행하면 현재 프로젝트 루트 아래 `data/raw` 경로가 출력됩니다. 이제 여기에 수집한 CSV 파일들을 저장하면 됩니다.

---

## Step 1. ETF 기본 정보 수집 (`etf_info.csv`)

이제 본격적으로 데이터를 수집해보겠습니다. 가장 먼저 수집할 데이터는 **ETF 기본 정보**입니다.

ETF 기본 정보에는 상장일, 운용사, 순자산총액(AUM), NAV, 괴리율, 추적오차 등 ETF의 메타데이터와 현재 상태를 나타내는 여러 필드가 포함됩니다. 이 정보들은 나중에 ETF의 규모를 비교하거나, 추적 성과를 평가하거나, 레버리지/인버스 여부를 판별할 때 사용됩니다.

### 1-1. ETF/ETN 현재가 API (`FHPST02400000`)

한국투자증권에서는 ETF 기본 정보를 조회할 수 있는 API를 제공합니다.

**API 정보:**

- PATH: `/uapi/etfetn/v1/quotations/inquire-price`
- TR_ID: `FHPST02400000`

이 API를 호출하면 ETF의 현재가뿐만 아니라, 운용사명, 상장일, 순자산총액, NAV, 괴리율, 추적오차, 배당주기 등 다양한 필드가 함께 반환됩니다.

**수집하는 주요 필드:**

| 컬럼명           | 설명            | 후속 활용            |
| ---------------- | --------------- | -------------------- |
| `stck_prpr`      | 현재가          | 괴리율 계산          |
| `nav`            | 순자산가치      | 괴리율 계산          |
| `etf_ntas_ttam`  | 순자산총액(AUM) | 규모 분석            |
| `mbcr_name`      | 운용사명        | 메타 정보            |
| `stck_lstn_date` | 상장일          | 운용 기간            |
| `etf_div_name`   | ETF 구분명      | 레버리지/인버스 판별 |
| `etf_dvdn_cycl`  | 배당주기        | 배당 분석            |
| `dprt`           | 괴리율          | 추적 성과            |
| `trc_errt`       | 추적오차        | 추적 성과            |

이 테이블을 보시면, 각 필드가 어떤 분석에 쓰이는지 알 수 있습니다. 예를 들어, `dprt`와 `trc_errt`는 ETF가 기초 지수를 얼마나 정확하게 추적하고 있는지 평가할 때 사용됩니다. `etf_ntas_ttam`은 AUM을 나타내는데, 이 값이 크면 유동성이 좋고 안정적인 운용이 가능하다는 의미입니다.

자, 이제 실제로 이 API를 호출하는 함수를 작성해보겠습니다.

```python
def fetch_etf_info_raw(etf_code: str) -> Dict[str, Any]:
    """
    ETF/ETN 현재가 API를 호출하여 ETF 기본 정보를 수집.

    반환: 원본 필드 그대로 담은 dict
    """
    path = "/uapi/etfetn/v1/quotations/inquire-price"
    tr_id = "FHPST02400000"

    etf_code = str(etf_code).strip().zfill(6)

    params = {
        "fid_input_iscd": etf_code,
        "fid_cond_mrkt_div_code": "J",
    }

    data = call_kis_get(path, tr_id, params)
    output = data.get("output") or {}

    if not output:
        raise RuntimeError(f"ETF 정보 조회 실패: etf_code={etf_code}")

    # 기본 정보 추출 (원본 그대로)
    row = {
        "ticker": etf_code,
        "name_kor": get_etf_name_from_kis(etf_code),

        # 상장/규모
        "listing_date": output.get("stck_lstn_date"),
        "aum": output.get("etf_ntas_ttam"),
        "lstn_stcn": output.get("lstn_stcn"),  # 상장좌수

        # 거래/유동성
        "last_price": output.get("stck_prpr"),
        "daily_volume": output.get("acml_vol"),
        "daily_tr_value": output.get("acml_tr_pbmn"),
        "prdy_volume": output.get("prdy_vol"),

        # NAV 관련
        "nav": output.get("nav"),
        "nav_prev": output.get("prdy_last_nav"),
        "dprt": output.get("dprt"),  # 괴리율
        "trc_errt": output.get("trc_errt"),  # 추적오차

        # 구조/유형
        "mbcr_name": output.get("mbcr_name"),  # 운용사명
        "etf_div_name": output.get("etf_div_name"),  # ETF 구분명
        "etf_dvdn_cycl": output.get("etf_dvdn_cycl"),  # 배당주기
        "etf_rprs_bstp_kor_isnm": output.get("etf_rprs_bstp_kor_isnm"),  # 대표 지수명

        # 기타 참고용
        "frgn_hldn_qty_rate": output.get("frgn_hldn_qty_rate"),  # 외국인 보유율
        "lp_hldn_rate": output.get("lp_hldn_rate"),  # LP 보유율
        "stck_dryy_hgpr": output.get("stck_dryy_hgpr"),  # 연중 최고
        "stck_dryy_lwpr": output.get("stck_dryy_lwpr"),  # 연중 최저
    }

    return row
```

코드를 잠깐 보시면, `call_kis_get()` 함수를 사용해서 API를 호출하고, 응답에서 `output` 필드를 꺼낸 뒤, 필요한 필드들을 딕셔너리 형태로 정리하고 있습니다.

여기서 중요한 점은, 이 단계에서는 **원본 필드를 그대로 유지**한다는 점입니다. 괴리율이 무엇인지, 추적오차가 어떤 의미인지 해석하지 않습니다. 그냥 API에서 온 값을 그대로 저장해두는 거죠. 해석과 가공은 10강에서 진행합니다.

### 1-2. 여러 ETF 정보 수집 및 저장

이제 여러 ETF를 배치로 수집하는 함수를 만들어보겠습니다.

```python
import time

def collect_etf_info_batch(
    etf_codes: List[str],
    *,
    sleep_sec: float = 0.1
) -> pd.DataFrame:
    """
    여러 ETF에 대해 기본 정보를 배치로 수집.
    """
    records = []

    for idx, code in enumerate(etf_codes, start=1):
        code = str(code).strip().zfill(6)
        print(f"[{idx}/{len(etf_codes)}] ETF 정보 수집: {code}")

        try:
            row = fetch_etf_info_raw(code)
            records.append(row)
        except Exception as e:
            print(f"  ⚠️ 수집 실패: {e}")
            continue

        time.sleep(sleep_sec)

    if not records:
        raise RuntimeError("ETF 정보 수집 결과가 없습니다.")

    df = pd.DataFrame(records)
    df["as_of_date"] = date.today().isoformat()

    return df


def save_etf_info(df: pd.DataFrame, filename: str = "etf_info.csv") -> Path:
    """
    ETF 기본 정보 DataFrame을 CSV로 저장.
    """
    path = RAW_DATA_DIR / filename
    df.to_csv(path, index=False, encoding="utf-8-sig")
    print(f"[SAVE] {path}")
    return path
```

`collect_etf_info_batch()` 함수는 ETF 코드 리스트를 받아서, 하나씩 순회하면서 `fetch_etf_info_raw()`를 호출합니다. 중간에 에러가 나더라도 멈추지 않고 다음 종목으로 넘어갑니다. 이렇게 하면, 일부 종목에서 문제가 생겨도 나머지 데이터는 수집할 수 있습니다.

`save_etf_info()` 함수는 DataFrame을 받아서 CSV로 저장합니다. 간단하죠.

### 1-3. 예시: KODEX 200 등 주요 ETF 정보 수집

이제 실제로 몇 개 ETF의 정보를 수집해보겠습니다. 예시로 KODEX 200 하나만 수집하겠습니다.

```python
# 수집할 ETF 코드 (예: KODEX 200)
sample_etfs = ["069500"]

# 배치 수집
df_etf_info = collect_etf_info_batch(sample_etfs)

# 저장
save_etf_info(df_etf_info)
```

실행하면 다음과 같은 메시지가 출력됩니다.

```
[1/1] ETF 정보 수집: 069500
[SAVE] /path/to/data/raw/etf_info.csv
```

잘 수집되었네요.

### 1-4. 데이터 검증 (최소한의 확인만)

수집한 데이터를 한 번 살펴보겠습니다. 여기서는 복잡한 검증을 하지 않습니다. 그저 데이터가 제대로 들어왔는지, 주요 컬럼이 비어있지 않은지 정도만 확인하면 됩니다.

```python
print("=" * 50)
print("ETF 기본 정보 검증")
print("=" * 50)

# Shape
print(f"\nShape: {df_etf_info.shape}")

# Columns
print(f"\nColumns:")
print(f"   {list(df_etf_info.columns)}")

# 주요 컬럼 결측 비율
print(f"\n주요 컬럼 결측 비율:")
key_cols = ["ticker", "name_kor", "aum", "last_price", "nav"]
for col in key_cols:
    if col in df_etf_info.columns:
        rate = df_etf_info[col].isna().mean()
        print(f"   - {col}: {rate:.1%}")

# 샘플 데이터
print(f"\n샘플 데이터:")
display(df_etf_info[["ticker", "name_kor", "aum", "last_price", "nav"]])
```

출력 결과를 보면, 필요한 컬럼들이 잘 채워져 있고, 결측값도 없다는 걸 확인할 수 있습니다. 이 정도면 충분합니다. 오늘은 "데이터를 깔끔하게 수집해두는 것"이 목표니까요.

---

## Step 2. ETF 구성 종목 수집 (`holdings_{ticker}.csv`)

다음으로 수집할 데이터는 **ETF 구성 종목**(Holdings)입니다.

ETF는 여러 주식을 묶어놓은 상품이기 때문에, "어떤 종목들로 구성되어 있는지"를 알아야 포트폴리오 분석을 할 수 있습니다. 예를 들어, KODEX 200은 KOSPI 200 지수를 추종하니까, 삼성전자, SK하이닉스, NAVER 같은 주요 종목들이 포함되어 있겠죠.

### 2-1. ETF 구성 종목 API (`FHKST13030300`)

한국투자증권에서는 ETF 구성 종목을 조회할 수 있는 API를 제공합니다.

**API 정보:**

- PATH: `/uapi/domestic-stock/v1/quotations/inquire-etf-comp-list`
- TR_ID: `FHKST13030300`

이 API를 호출하면 ETF를 구성하는 종목의 코드, 이름, 비중 등이 반환됩니다.

**수집하는 주요 필드:**

| 컬럼명               | 설명         | 후속 활용       |
| -------------------- | ------------ | --------------- |
| `mksc_shrn_iscd`     | 종목 코드    | 종목 식별       |
| `hts_kor_isnm`       | 종목명       | 메타 정보       |
| `bskt_cmpn_rate`     | 구성 비중(%) | 포트폴리오 분석 |
| `prdt_avrg_stck_qty` | 평균 주식 수 | 포지션 분석     |

구성 비중(`bskt_cmpn_rate`)은 10강에서 섹터 분포나 시가총액 분포를 계산할 때 사용됩니다. 어떤 종목이 몇 퍼센트를 차지하는지 알면, ETF가 특정 섹터에 집중되어 있는지, 아니면 고르게 분산되어 있는지 파악할 수 있습니다.

자, 이제 실제로 API를 호출하는 함수를 작성해보겠습니다.

```python
def fetch_etf_holdings_raw(etf_code: str) -> pd.DataFrame:
    """
    ETF 구성 종목 API를 호출하여 Holdings 정보를 수집.

    반환: 구성 종목 DataFrame
    """
    path = "/uapi/domestic-stock/v1/quotations/inquire-etf-comp-list"
    tr_id = "FHKST13030300"

    etf_code = str(etf_code).strip().zfill(6)

    params = {
        "fid_input_iscd": etf_code,
        "fid_input_cnt_1": "0",
        "fid_prc_cls_code": "0",
    }

    data = call_kis_get(path, tr_id, params)
    output2 = data.get("output2") or []

    if not output2:
        raise RuntimeError(f"ETF 구성 종목 조회 실패: etf_code={etf_code}")

    # DataFrame 변환
    df = pd.DataFrame(output2)

    # 주요 컬럼만 선택
    cols_map = {
        "mksc_shrn_iscd": "ticker",
        "hts_kor_isnm": "name_kor",
        "bskt_cmpn_rate": "weight_pct",
        "prdt_avrg_stck_qty": "avg_qty",
    }

    for old_col, new_col in cols_map.items():
        if old_col in df.columns:
            df[new_col] = df[old_col]

    # ETF 코드 추가
    df["etf_ticker"] = etf_code

    return df
```

코드를 보시면, API 응답에서 `output2` 필드를 꺼내서 DataFrame으로 변환하고 있습니다. 컬럼명을 조금 더 이해하기 쉽게 바꿔주고, `etf_ticker` 컬럼을 추가해서 어느 ETF의 구성 종목인지 표시해줍니다.

### 2-2. 구성 종목 저장

이제 수집한 구성 종목 데이터를 CSV로 저장하는 함수를 만들어보겠습니다.

```python
def save_etf_holdings(df: pd.DataFrame, etf_code: str) -> Path:
    """
    ETF 구성 종목 DataFrame을 CSV로 저장.
    """
    etf_code = str(etf_code).strip().zfill(6)
    filename = f"holdings_{etf_code}.csv"
    path = RAW_DATA_DIR / filename
    df.to_csv(path, index=False, encoding="utf-8-sig")
    print(f"[SAVE] {path}")
    return path
```

파일명에 ETF 코드를 붙여서, 나중에 어느 ETF의 구성 종목인지 쉽게 알 수 있도록 했습니다.

### 2-3. 예시: KODEX 200 구성 종목 수집

이제 실제로 KODEX 200의 구성 종목을 수집해보겠습니다.

```python
# KODEX 200 구성 종목 수집
example_etf = "069500"
df_holdings = fetch_etf_holdings_raw(example_etf)

# 저장
save_etf_holdings(df_holdings, example_etf)
```

실행하면 다음과 같은 메시지가 출력됩니다.

```
[SAVE] /path/to/data/raw/holdings_069500.csv
```

잘 수집되었네요.

### 2-4. 데이터 검증 (최소한의 확인만)

수집한 데이터를 한 번 살펴보겠습니다.

```python
print("=" * 50)
print("ETF 구성 종목 검증")
print("=" * 50)

# Shape
print(f"\nShape: {df_holdings.shape}")

# Columns
print(f"\nColumns:")
print(f"   {list(df_holdings.columns)}")

# 주요 컬럼 결측 비율
print(f"\n주요 컬럼 결측 비율:")
key_cols = ["ticker", "name_kor", "weight_pct"]
for col in key_cols:
    if col in df_holdings.columns:
        rate = df_holdings[col].isna().mean()
        print(f"   - {col}: {rate:.1%}")

# 비중 합계 확인
if "weight_pct" in df_holdings.columns:
    weight_sum = pd.to_numeric(df_holdings["weight_pct"], errors="coerce").sum()
    print(f"\n비중 합계: {weight_sum:.2f}%")

# 샘플 데이터
print(f"\n샘플 데이터 (상위 10개 종목):")
display(df_holdings.head(10)[["ticker", "name_kor", "weight_pct"]])
```

출력 결과를 보면, 종목 코드, 종목명, 비중이 잘 채워져 있고, 비중 합계가 거의 100%에 가까운 걸 확인할 수 있습니다. 완벽하진 않더라도, 데이터가 정상적으로 수집되었다는 건 충분히 알 수 있습니다.

---

## Step 3. ETF 가격 시계열 수집 (`price_{ticker}.csv`)

마지막으로 수집할 데이터는 **ETF 가격 시계열**입니다.

가격 시계열은 수익률, 변동성, MDD 같은 리스크 지표를 계산할 때 필요합니다. 11강에서 이 데이터를 사용해서 월별 수익률, 연간 수익률, Sharpe Ratio 등을 계산할 예정입니다.

### 3-1. 국내 주식 일자별 시세 API (`FHKST03010100`)

한국투자증권에서는 국내 주식과 ETF의 일자별 시세를 조회할 수 있는 API를 제공합니다.

**API 정보:**

- PATH: `/uapi/domestic-stock/v1/quotations/inquire-daily-itemchartprice`
- TR_ID: `FHKST03010100`

이 API는 지정한 기간 동안의 일별 가격 데이터를 반환합니다.

**수집하는 주요 필드:**

| 컬럼명           | 설명     | 후속 활용   |
| ---------------- | -------- | ----------- |
| `stck_bsop_date` | 영업일자 | 날짜 인덱스 |
| `stck_clpr`      | 종가     | 수익률 계산 |
| `stck_oprc`      | 시가     | 가격 범위   |
| `stck_hgpr`      | 고가     | 가격 범위   |
| `stck_lwpr`      | 저가     | 가격 범위   |
| `acml_vol`       | 거래량   | 유동성 분석 |
| `acml_tr_pbmn`   | 거래대금 | 유동성 분석 |

종가(`stck_clpr`)는 수익률 계산의 기본이 됩니다. 거래량(`acml_vol`)과 거래대금(`acml_tr_pbmn`)은 유동성을 평가할 때 사용됩니다.

자, 이제 실제로 API를 호출하는 함수를 작성해보겠습니다.

```python
def fetch_daily_price_range(
    etf_code: str,
    start_date: str,
    end_date: str,
) -> pd.DataFrame:
    """
    ETF 일별 가격 시계열 수집 (특정 기간).

    Args:
        etf_code: ETF 코드 (6자리)
        start_date: 시작일 (YYYYMMDD)
        end_date: 종료일 (YYYYMMDD)

    반환: 일별 가격 DataFrame
    """
    path = "/uapi/domestic-stock/v1/quotations/inquire-daily-itemchartprice"
    tr_id = "FHKST03010100"

    etf_code = str(etf_code).strip().zfill(6)

    params = {
        "fid_input_iscd": etf_code,
        "fid_input_date_1": start_date,
        "fid_input_date_2": end_date,
        "fid_period_div_code": "D",
        "fid_org_adj_prc": "0",
    }

    data = call_kis_get(path, tr_id, params)
    output2 = data.get("output2") or []

    if not output2:
        raise RuntimeError(f"가격 시계열 조회 실패: etf_code={etf_code}, {start_date}~{end_date}")

    # DataFrame 변환
    df = pd.DataFrame(output2)

    # 날짜 변환
    if "stck_bsop_date" in df.columns:
        df["date"] = pd.to_datetime(df["stck_bsop_date"], format="%Y%m%d", errors="coerce")

    # 숫자 컬럼 변환
    numeric_cols = ["stck_clpr", "stck_oprc", "stck_hgpr", "stck_lwpr", "acml_vol", "acml_tr_pbmn"]
    for col in numeric_cols:
        if col in df.columns:
            df[f"{col}_float"] = df[col].apply(to_float)

    # ETF 코드 추가
    df["code"] = etf_code

    return df
```

코드를 보시면, API 응답에서 `output2` 필드를 꺼내서 DataFrame으로 변환하고 있습니다. 날짜 컬럼(`stck_bsop_date`)을 `datetime` 타입으로 변환하고, 가격이나 거래량 같은 숫자 컬럼들은 `to_float()` 함수를 사용해서 쉼표를 제거하고 float로 변환합니다.

### 3-2. 가격 시계열 저장

이제 수집한 가격 시계열 데이터를 CSV로 저장하는 함수를 만들어보겠습니다.

```python
def save_etf_price(df: pd.DataFrame, etf_code: str) -> Path:
    """
    ETF 가격 시계열 DataFrame을 CSV로 저장.
    """
    etf_code = str(etf_code).strip().zfill(6)
    filename = f"price_{etf_code}.csv"
    path = RAW_DATA_DIR / filename
    df.to_csv(path, index=False, encoding="utf-8-sig")
    print(f"[SAVE] {path}")
    return path
```

파일명에 ETF 코드를 붙여서, 나중에 어느 ETF의 가격 데이터인지 쉽게 알 수 있도록 했습니다.

### 3-3. 예시: KODEX 200 가격 시계열 수집 (최근 1년)

이제 실제로 KODEX 200의 최근 1년 가격 데이터를 수집해보겠습니다.

```python
# KODEX 200 가격 시계열 수집 (최근 1년)
example_etf = "069500"

end_dt = date.today()
start_dt = end_dt - timedelta(days=365)

start_date = start_dt.strftime("%Y%m%d")
end_date = end_dt.strftime("%Y%m%d")

print(f"수집 기간: {start_date} ~ {end_date}")

df_price = fetch_daily_price_range(example_etf, start_date, end_date)

# 저장
if not df_price.empty:
    save_etf_price(df_price, example_etf)
```

실행하면 다음과 같은 메시지가 출력됩니다.

```
수집 기간: 20241202 ~ 20251201
[SAVE] /path/to/data/raw/price_069500.csv
```

잘 수집되었네요.

### 3-4. 데이터 검증 (최소한의 확인만)

수집한 데이터를 한 번 살펴보겠습니다.

```python
print("=" * 50)
print("ETF 가격 시계열 검증")
print("=" * 50)

# Shape
print(f"\nShape: {df_price.shape}")

# Columns
print(f"\nColumns:")
print(f"   {list(df_price.columns)}")

# 기간 확인
print(f"\n기간:")
print(f"   - 시작: {df_price['date'].min()}")
print(f"   - 종료: {df_price['date'].max()}")
print(f"   - 거래일 수: {len(df_price)}")

# 결측 비율 (주요 컬럼만)
print(f"\n결측 비율 (주요 컬럼):")
key_cols = ["date", "stck_clpr_float", "acml_vol_float"]
for col in key_cols:
    if col in df_price.columns:
        rate = df_price[col].isna().mean()
        print(f"   - {col}: {rate:.1%}")

# 키 중복 체크
dup_count = df_price.duplicated(subset=["code", "date"]).sum()
print(f"\n키 중복 (code, date): {dup_count}개")

# 샘플 데이터
print(f"\n샘플 데이터 (최근 5일):")
display(df_price.tail()[["date", "stck_clpr_float", "acml_vol_float"]])
```

출력 결과를 보면, 날짜, 종가, 거래량이 잘 채워져 있고, 중복된 날짜도 없다는 걸 확인할 수 있습니다. 거래일 수가 약 242일 정도 나오는데, 이건 영업일 기준이니까 정상입니다.

---

## 정리: 수집된 로우 데이터

자, 이제 오늘 수집한 데이터를 한 번 정리해보겠습니다.

```python
import os

print("=" * 60)
print("9강 수집 완료: 로우 데이터 목록")
print("=" * 60)

# 저장된 파일 목록
print(f"\n저장 디렉터리: {RAW_DATA_DIR}")
print(f"\n저장된 파일:")

for f in sorted(RAW_DATA_DIR.glob("*.csv")):
    size_kb = f.stat().st_size / 1024
    print(f"  - {f.name} ({size_kb:.1f} KB)")

print("\n" + "=" * 60)
print("10강에서는 이 데이터를 읽어서 기본·포트폴리오 지표를 계산합니다.")
print("11강에서는 가격 시계열로 수익률·리스크 지표를 계산합니다.")
print("=" * 60)
```

실행하면 다음과 같은 출력이 나옵니다.

```
============================================================
9강 수집 완료: 로우 데이터 목록
============================================================

저장 디렉터리: /path/to/data/raw

저장된 파일:
  - etf_info.csv (1.1 KB)
  - holdings_069500.csv (15.3 KB)
  - price_069500.csv (35.1 KB)

============================================================
10강에서는 이 데이터를 읽어서 기본·포트폴리오 지표를 계산합니다.
11강에서는 가격 시계열로 수익률·리스크 지표를 계산합니다.
============================================================
```

오늘 수집한 세 가지 핵심 데이터셋이 모두 CSV 파일로 잘 저장되어 있습니다. 이 파일들은 다음 강의에서 분석 재료로 사용됩니다.

---

## 📌 참고: 벤치마크 지수 시계열

한 가지 더 말씀드릴 게 있습니다. 벤치마크 지수(KOSPI, KOSPI 200 등) 시계열 데이터는 오늘 수집하지 않습니다.

이 데이터는 **11강**에서 "위험·상대지표"를 설명할 때 함께 수집하겠습니다. 왜냐하면, 벤치마크 지수는 Beta나 상대 수익률 같은 지표를 계산할 때 필요한데, 이런 지표들이 바로 11강의 주제이기 때문입니다.

참고로, 벤치마크 지수 시계열을 수집할 때는 다음 API를 사용합니다.

**API 정보:**

- PATH: `/uapi/domestic-stock/v1/quotations/inquire-daily-indexchartprice`
- TR_ID: `FHKUP03500100`
- `FID_COND_MRKT_DIV_CODE`: "U" (업종)

**지수 코드 예시:**

- `0001`: KOSPI
- `2001`: KOSPI 200
- `2203`: KOSDAQ 150

이 정도만 알아두시면 11강에서 바로 활용할 수 있습니다.

---

## 마무리

오늘 강의에서는 ETF 분석에 필요한 **세 가지 핵심 데이터셋**을 정의하고, 한국투자증권 API를 통해 실제로 수집한 뒤, CSV 파일로 저장하는 과정까지 함께 해보았습니다.

**먼저**, ETF 기본 정보를 수집해서 `etf_info.csv`에 저장했습니다. 여기에는 상장일, AUM, NAV, 괴리율, 추적오차 같은 메타데이터가 담겨 있습니다.

**그다음**, ETF 구성 종목을 수집해서 `holdings_{ticker}.csv`에 저장했습니다. 어떤 종목들로 구성되어 있는지, 각 종목의 비중이 얼마인지 알 수 있습니다.

**마지막으로**, ETF 가격 시계열을 수집해서 `price_{ticker}.csv`에 저장했습니다. 이 데이터는 수익률과 리스크 지표를 계산할 때 사용됩니다.

오늘 우리가 수집한 데이터는 **10강과 11강의 분석 재료**가 됩니다. 10강에서는 ETF의 기본 지표와 포트폴리오 구성을 분석하고, 11강에서는 가격 시계열을 바탕으로 수익률과 리스크 지표를 계산할 예정입니다.

여러분도 지금 진행 중인 프로젝트에서, 분석에 필요한 로우 데이터를 먼저 깔끔하게 수집해두는 습관을 들이시면 좋겠습니다. 데이터 수집과 분석을 분리해두면, 나중에 분석 로직만 따로 수정하거나 확장할 때 훨씬 편리합니다.

잘 정리해두셨다가, 다음 강의에서 이어서 사용해보겠습니다. 오늘 수고하셨습니다.
